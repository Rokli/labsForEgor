{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0de173fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msvm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SVC\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mneighbors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KNeighborsClassifier\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m layers, callbacks\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                             f1_score, roc_auc_score, roc_curve, confusion_matrix)\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, ComplementNB, BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, callbacks\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1efeab8",
   "metadata": {},
   "source": [
    "### Загрузка датасета Breast Cancer Wisconsin\n",
    "Этот датасет содержит информацию о диагностике рака груди по признакам опухоли."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2219083a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer = datasets.load_breast_cancer()\n",
    "X = cancer.data\n",
    "y = cancer.target\n",
    "feature_names = cancer.feature_names\n",
    "target_names = cancer.target_names\n",
    "\n",
    "print(\"Информация о датасете:\")\n",
    "print(f\"Количество образцов: {X.shape[0]}\")\n",
    "print(f\"Количество признаков: {X.shape[1]}\")\n",
    "print(f\"Классы: {target_names}\")\n",
    "print(f\"Распределение классов: {np.bincount(y)}\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"\\nРазмер обучающей выборки: {X_train_scaled.shape}\")\n",
    "print(f\"Размер тестовой выборки: {X_test_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b7670b",
   "metadata": {},
   "source": [
    "\n",
    "### Визуализация распределения классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e90b947",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "axes[0].bar(target_names, np.bincount(y), color=['lightcoral', 'lightblue'])\n",
    "axes[0].set_title('Распределение классов в датасете')\n",
    "axes[0].set_xlabel('Класс')\n",
    "axes[0].set_ylabel('Количество')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "for i, count in enumerate(np.bincount(y)):\n",
    "    axes[0].text(i, count + 5, str(count), ha='center', va='bottom', fontsize=12)\n",
    "\n",
    "train_counts = np.bincount(y_train)\n",
    "test_counts = np.bincount(y_test)\n",
    "\n",
    "x = np.arange(len(target_names))\n",
    "width = 0.35\n",
    "axes[1].bar(x - width/2, train_counts, width, label='Обучающая', color='skyblue')\n",
    "axes[1].bar(x + width/2, test_counts, width, label='Тестовая', color='lightcoral')\n",
    "axes[1].set_title('Распределение классов в выборках')\n",
    "axes[1].set_xlabel('Класс')\n",
    "axes[1].set_ylabel('Количество')\n",
    "axes[1].set_xticks(x)\n",
    "axes[1].set_xticklabels(target_names)\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('class_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607abc5c",
   "metadata": {},
   "source": [
    "### Функции для оценки моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64f9fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, X_test, y_train, y_test, model_name=\"\"):\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    y_test_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "    \n",
    "    metrics = {\n",
    "        'Model': model_name,\n",
    "        'Train Accuracy': accuracy_score(y_train, y_train_pred),\n",
    "        'Test Accuracy': accuracy_score(y_test, y_test_pred),\n",
    "        'Test Precision': precision_score(y_test, y_test_pred, average='weighted'),\n",
    "        'Test Recall': recall_score(y_test, y_test_pred, average='weighted'),\n",
    "        'Test F1-Score': f1_score(y_test, y_test_pred, average='weighted'),\n",
    "        'Test ROC-AUC': roc_auc_score(y_test, y_test_proba) if y_test_proba is not None else None\n",
    "    }\n",
    "    \n",
    "    return metrics, y_test_pred, y_test_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf6661b",
   "metadata": {},
   "source": [
    "### Функции для визуализации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a6c9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics_comparison(metrics_df):\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    metrics_to_plot = ['Test Accuracy', 'Test Precision', 'Test Recall', \n",
    "                       'Test F1-Score', 'Test ROC-AUC']\n",
    "    \n",
    "    for i, metric in enumerate(metrics_to_plot):\n",
    "        if metric in metrics_df.columns:\n",
    "            ax = axes[i]\n",
    "            bars = ax.bar(range(len(metrics_df)), metrics_df[metric].values)\n",
    "            ax.set_title(metric, fontsize=12, fontweight='bold')\n",
    "            ax.set_xticks(range(len(metrics_df)))\n",
    "            ax.set_xticklabels(metrics_df['Model'].values, rotation=45, ha='right')\n",
    "            ax.set_ylim([0.8, 1.0])\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            \n",
    "            for bar, value in zip(bars, metrics_df[metric].values):\n",
    "                height = bar.get_height()\n",
    "                ax.text(bar.get_x() + bar.get_width()/2., height + 0.005,\n",
    "                        f'{value:.3f}', ha='center', va='bottom', fontsize=9,\n",
    "                        fontweight='bold' if value == max(metrics_df[metric].values) else 'normal')\n",
    "    \n",
    "    plt.suptitle('Сравнение метрик классификаторов', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('metrics_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def plot_roc_curves(models_results, y_test):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    for model_name, results in models_results.items():\n",
    "        y_test_proba = results['y_test_proba']\n",
    "        if y_test_proba is not None:\n",
    "            fpr, tpr, _ = roc_curve(y_test, y_test_proba)\n",
    "            auc_score = roc_auc_score(y_test, y_test_proba)\n",
    "            plt.plot(fpr, tpr, label=f'{model_name} (AUC = {auc_score:.3f})', linewidth=2)\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], 'k--', label='Случайный классификатор')\n",
    "    plt.xlabel('False Positive Rate', fontsize=12)\n",
    "    plt.ylabel('True Positive Rate', fontsize=12)\n",
    "    plt.title('ROC-кривые классификаторов', fontsize=14, fontweight='bold')\n",
    "    plt.legend(loc='lower right', fontsize=10)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.savefig('roc_curves.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix_comparison(models_results, y_test, target_names):\n",
    "    n_models = len(models_results)\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, (model_name, results) in enumerate(list(models_results.items())[:6]):\n",
    "        ax = axes[idx]\n",
    "        cm = confusion_matrix(y_test, results['y_pred'])\n",
    "        \n",
    "        cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        \n",
    "        im = ax.imshow(cm_normalized, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "        ax.set_title(f'{model_name}', fontsize=11, fontweight='bold')\n",
    "        \n",
    "        thresh = cm_normalized.max() / 2.\n",
    "        for i in range(cm_normalized.shape[0]):\n",
    "            for j in range(cm_normalized.shape[1]):\n",
    "                ax.text(j, i, f'{cm[i, j]}\\n({cm_normalized[i, j]:.2%})',\n",
    "                       ha=\"center\", va=\"center\",\n",
    "                       color=\"white\" if cm_normalized[i, j] > thresh else \"black\",\n",
    "                       fontsize=9)\n",
    "        \n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        ax.set_xticks(tick_marks)\n",
    "        ax.set_xticklabels(target_names)\n",
    "        ax.set_yticks(tick_marks)\n",
    "        ax.set_yticklabels(target_names)\n",
    "        ax.set_ylabel('Истинный класс')\n",
    "        ax.set_xlabel('Предсказанный класс')\n",
    "    \n",
    "    plt.suptitle('Матрицы ошибок классификаторов', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('confusion_matrices.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a833d5",
   "metadata": {},
   "source": [
    "### Обучение и оценка моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8932cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics = []\n",
    "models_results = {}\n",
    "\n",
    "gnb = GaussianNB()\n",
    "metrics, y_pred, y_proba = evaluate_model(gnb, X_train_scaled, X_test_scaled, \n",
    "                                          y_train, y_test, \"GaussianNB\")\n",
    "all_metrics.append(metrics)\n",
    "models_results['GaussianNB'] = {'y_pred': y_pred, 'y_test_proba': y_proba}\n",
    "\n",
    "X_train_nonneg = X_train_scaled - X_train_scaled.min()\n",
    "X_test_nonneg = X_test_scaled - X_test_scaled.min()\n",
    "mnb = MultinomialNB()\n",
    "metrics, y_pred, y_proba = evaluate_model(mnb, X_train_nonneg, X_test_nonneg, \n",
    "                                          y_train, y_test, \"MultinomialNB\")\n",
    "all_metrics.append(metrics)\n",
    "models_results['MultinomialNB'] = {'y_pred': y_pred, 'y_test_proba': y_proba}\n",
    "\n",
    "bnb = BernoulliNB(binarize=0.0)\n",
    "metrics, y_pred, y_proba = evaluate_model(bnb, X_train_scaled, X_test_scaled, \n",
    "                                          y_train, y_test, \"BernoulliNB\")\n",
    "all_metrics.append(metrics)\n",
    "models_results['BernoulliNB'] = {'y_pred': y_pred, 'y_test_proba': y_proba}\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"2. ДЕРЕВЬЯ РЕШЕНИЙ\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "param_grid_dt = {\n",
    "    'max_depth': [3, 5, 7, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "grid_search_dt = GridSearchCV(dt, param_grid_dt, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search_dt.fit(X_train_scaled, y_train)\n",
    "\n",
    "best_dt = grid_search_dt.best_estimator_\n",
    "metrics, y_pred, y_proba = evaluate_model(best_dt, X_train_scaled, X_test_scaled, \n",
    "                                          y_train, y_test, \"Decision Tree\")\n",
    "all_metrics.append(metrics)\n",
    "models_results['Decision Tree'] = {'y_pred': y_pred, 'y_test_proba': y_proba}\n",
    "\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "metrics, y_pred, y_proba = evaluate_model(lda, X_train_scaled, X_test_scaled, \n",
    "                                          y_train, y_test, \"LDA\")\n",
    "all_metrics.append(metrics)\n",
    "models_results['LDA'] = {'y_pred': y_pred, 'y_test_proba': y_proba}\n",
    "\n",
    "svm = SVC(probability=True, random_state=42, C=1.0, gamma='scale', kernel='rbf')\n",
    "metrics, y_pred, y_proba = evaluate_model(svm, X_train_scaled, X_test_scaled, \n",
    "                                          y_train, y_test, \"SVM\")\n",
    "all_metrics.append(metrics)\n",
    "models_results['SVM'] = {'y_pred': y_pred, 'y_test_proba': y_proba}\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5, weights='distance', metric='euclidean')\n",
    "metrics, y_pred, y_proba = evaluate_model(knn, X_train_scaled, X_test_scaled, \n",
    "                                          y_train, y_test, \"KNN\")\n",
    "all_metrics.append(metrics)\n",
    "models_results['KNN'] = {'y_pred': y_pred, 'y_test_proba': y_proba}\n",
    "\n",
    "metrics_df = pd.DataFrame(all_metrics)\n",
    "print(\"\\nСводная таблица метрик классификаторов:\")\n",
    "print(metrics_df.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32657628",
   "metadata": {},
   "source": [
    "### Сравнение метрик классификаторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8793e1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics_comparison(metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7416974",
   "metadata": {},
   "source": [
    "### ROC-кривые классификаторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5109106e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curves(models_results, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6a39f9",
   "metadata": {},
   "source": [
    "### Матрицы ошибок классификаторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e37ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix_comparison(models_results, y_test, target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1e8a87",
   "metadata": {},
   "source": [
    "### Создание и обучение нейронной сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6084e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_nn = X_train_scaled\n",
    "X_test_nn = X_test_scaled\n",
    "y_train_nn = y_train\n",
    "y_test_nn = y_test\n",
    "\n",
    "def create_nn_model(learning_rate=0.001, hidden_units=32, dropout_rate=0.2):\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(X_train_nn.shape[1],)),\n",
    "        layers.Dense(hidden_units, activation='relu'),\n",
    "        layers.Dropout(dropout_rate),\n",
    "        layers.Dense(hidden_units//2, activation='relu'),\n",
    "        layers.Dropout(dropout_rate/2),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', \n",
    "                 keras.metrics.Precision(name='precision'),\n",
    "                 keras.metrics.Recall(name='recall'),\n",
    "                 keras.metrics.AUC(name='auc')]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "nn_model = create_nn_model(learning_rate=0.001, hidden_units=32, dropout_rate=0.2)\n",
    "\n",
    "early_stopping_callback = callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = nn_model.fit(\n",
    "    X_train_nn, y_train_nn,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[early_stopping_callback]\n",
    ")\n",
    "\n",
    "test_results = nn_model.evaluate(X_test_nn, y_test_nn, verbose=0)\n",
    "print(\"\\nРезультаты нейронной сети на тестовых данных:\")\n",
    "print(f\"Test Loss: {test_results[0]:.4f}\")\n",
    "print(f\"Test Accuracy: {test_results[1]:.4f}\")\n",
    "print(f\"Test Precision: {test_results[2]:.4f}\")\n",
    "print(f\"Test Recall: {test_results[3]:.4f}\")\n",
    "print(f\"Test AUC: {test_results[4]:.4f}\")\n",
    "\n",
    "y_test_pred_nn = (nn_model.predict(X_test_nn) > 0.5).astype(\"int32\").flatten()\n",
    "y_test_proba_nn = nn_model.predict(X_test_nn).flatten()\n",
    "\n",
    "nn_metrics = {\n",
    "    'Model': 'Neural Network',\n",
    "    'Train Accuracy': history.history['accuracy'][-1],\n",
    "    'Test Accuracy': test_results[1],\n",
    "    'Test Precision': test_results[2],\n",
    "    'Test Recall': test_results[3],\n",
    "    'Test F1-Score': 2 * (test_results[2] * test_results[3]) / (test_results[2] + test_results[3]),\n",
    "    'Test ROC-AUC': test_results[4]\n",
    "}\n",
    "\n",
    "all_metrics.append(nn_metrics)\n",
    "models_results['Neural Network'] = {'y_pred': y_test_pred_nn, 'y_test_proba': y_test_proba_nn}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3881df83",
   "metadata": {},
   "source": [
    "### Графики обучения нейронной сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2097944",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "axes[0, 0].plot(history.history['accuracy'], label='Точность на обучении', linewidth=2)\n",
    "axes[0, 0].plot(history.history['val_accuracy'], label='Точность на валидации', linewidth=2)\n",
    "axes[0, 0].set_title('Точность модели', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Эпоха')\n",
    "axes[0, 0].set_ylabel('Точность')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[0, 1].plot(history.history['loss'], label='Потери на обучении', linewidth=2)\n",
    "axes[0, 1].plot(history.history['val_loss'], label='Потери на валидации', linewidth=2)\n",
    "axes[0, 1].set_title('Потери модели', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Эпоха')\n",
    "axes[0, 1].set_ylabel('Потери')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1, 0].plot(history.history['precision'], label='Precision на обучении', linewidth=2)\n",
    "axes[1, 0].plot(history.history['val_precision'], label='Precision на валидации', linewidth=2, linestyle='--')\n",
    "axes[1, 0].plot(history.history['recall'], label='Recall на обучении', linewidth=2)\n",
    "axes[1, 0].plot(history.history['val_recall'], label='Recall на валидации', linewidth=2, linestyle='--')\n",
    "axes[1, 0].set_title('Precision и Recall', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Эпоха')\n",
    "axes[1, 0].set_ylabel('Score')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1, 1].plot(history.history['auc'], label='AUC на обучении', linewidth=2)\n",
    "axes[1, 1].plot(history.history['val_auc'], label='AUC на валидации', linewidth=2)\n",
    "axes[1, 1].set_title('AUC (Площадь под ROC-кривой)', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Эпоха')\n",
    "axes[1, 1].set_ylabel('AUC')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Процесс обучения нейронной сети', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('nn_training_history.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952e73ed",
   "metadata": {},
   "source": [
    "### ROC-кривая нейронной сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d99faf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_nn, tpr_nn, _ = roc_curve(y_test, y_test_proba_nn)\n",
    "auc_nn = roc_auc_score(y_test, y_test_proba_nn)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_nn, tpr_nn, label=f'Нейронная сеть (AUC = {auc_nn:.3f})', \n",
    "         linewidth=3, color='darkorange')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Случайный классификатор', linewidth=2)\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('ROC-кривая нейронной сети', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc='lower right', fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axis([0, 1, 0, 1])\n",
    "plt.savefig('nn_roc_curve.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3daa0dde",
   "metadata": {},
   "source": [
    "### Исследование влияния гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2695c052",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [0.1, 0.01, 0.001]\n",
    "hidden_units_list = [16, 32, 64]\n",
    "dropout_rates = [0.0, 0.2, 0.5]\n",
    "\n",
    "results = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for units in hidden_units_list:\n",
    "        for dropout in dropout_rates:\n",
    "            print(f\"Обучение: lr={lr}, units={units}, dropout={dropout}\")\n",
    "            \n",
    "            model = create_nn_model(\n",
    "                learning_rate=lr,\n",
    "                hidden_units=units,\n",
    "                dropout_rate=dropout\n",
    "            )\n",
    "            \n",
    "            history = model.fit(\n",
    "                X_train_nn, y_train_nn,\n",
    "                epochs=20,\n",
    "                batch_size=32,\n",
    "                validation_split=0.2,\n",
    "                verbose=0\n",
    "            )\n",
    "            \n",
    "            test_loss, test_acc, test_prec, test_rec, test_auc = model.evaluate(\n",
    "                X_test_nn, y_test_nn, verbose=0\n",
    "            )\n",
    "            \n",
    "            results.append({\n",
    "                'lr': lr,\n",
    "                'units': units,\n",
    "                'dropout': dropout,\n",
    "                'val_accuracy': max(history.history['val_accuracy']),\n",
    "                'test_accuracy': test_acc,\n",
    "                'test_auc': test_auc\n",
    "            })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nРезультаты исследования гиперпараметров:\")\n",
    "print(results_df.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08da1a1e",
   "metadata": {},
   "source": [
    "### Визуализация влияния гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a70f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "for lr in sorted(results_df['lr'].unique()):\n",
    "    lr_data = results_df[results_df['lr'] == lr]\n",
    "    axes[0].plot(lr_data['units'], lr_data['test_accuracy'], \n",
    "                marker='o', linewidth=2, markersize=8, label=f'lr={lr}')\n",
    "\n",
    "axes[0].set_xlabel('Количество нейронов', fontsize=11)\n",
    "axes[0].set_ylabel('Точность на тесте', fontsize=11)\n",
    "axes[0].set_title('Влияние Learning Rate', fontsize=12, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "for dropout in sorted(results_df['dropout'].unique()):\n",
    "    dropout_data = results_df[results_df['dropout'] == dropout]\n",
    "    axes[1].plot(dropout_data['units'], dropout_data['test_accuracy'], \n",
    "                marker='s', linewidth=2, markersize=8, label=f'dropout={dropout}')\n",
    "\n",
    "axes[1].set_xlabel('Количество нейронов', fontsize=11)\n",
    "axes[1].set_ylabel('Точность на тесте', fontsize=11)\n",
    "axes[1].set_title('Влияние Dropout', fontsize=12, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "for units in sorted(results_df['units'].unique()):\n",
    "    units_data = results_df[results_df['units'] == units]\n",
    "    axes[2].scatter(units_data['lr'], units_data['test_auc'], \n",
    "                   s=units_data['dropout']*200 + 50, alpha=0.6, \n",
    "                   label=f'{units} нейронов')\n",
    "\n",
    "axes[2].set_xlabel('Learning Rate', fontsize=11)\n",
    "axes[2].set_ylabel('AUC на тесте', fontsize=11)\n",
    "axes[2].set_title('Влияние архитектуры на AUC', fontsize=12, fontweight='bold')\n",
    "axes[2].set_xscale('log')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Исследование гиперпараметров нейронной сети', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('hyperparameters_study.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b7d3a5",
   "metadata": {},
   "source": [
    "\n",
    "### Финальная таблица сравнения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06e3d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_metrics_df = pd.DataFrame(all_metrics)\n",
    "print(\"\\nФИНАЛЬНОЕ СРАВНЕНИЕ ВСЕХ МОДЕЛЕЙ:\")\n",
    "print(\"=\"*60)\n",
    "print(final_metrics_df.round(3).sort_values('Test Accuracy', ascending=False))\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d66a4a",
   "metadata": {},
   "source": [
    "### Финальная визуализация сравнения всех моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f6888a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "models = final_metrics_df['Model'].values\n",
    "x = np.arange(len(models))\n",
    "width = 0.15\n",
    "\n",
    "metrics_to_compare = ['Test Accuracy', 'Test Precision', 'Test Recall', \n",
    "                      'Test F1-Score', 'Test ROC-AUC']\n",
    "\n",
    "colors = ['#3498db', '#2ecc71', '#e74c3c', '#f39c12', '#9b59b6']\n",
    "\n",
    "for i, (metric, color) in enumerate(zip(metrics_to_compare, colors)):\n",
    "    plt.bar(x + i*width - 2*width, final_metrics_df[metric].values, \n",
    "           width=width, label=metric, color=color, alpha=0.8)\n",
    "\n",
    "plt.xlabel('Модели классификации', fontsize=12)\n",
    "plt.ylabel('Значение метрики', fontsize=12)\n",
    "plt.title('Финальное сравнение всех классификаторов', fontsize=14, fontweight='bold')\n",
    "plt.xticks(x, models, rotation=45, ha='right', fontsize=10)\n",
    "plt.ylim([0.85, 1.01])\n",
    "plt.legend(loc='lower right', fontsize=10)\n",
    "plt.grid(True, axis='y', alpha=0.3)\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    best_metric = final_metrics_df.loc[final_metrics_df['Model'] == model, 'Test Accuracy'].values[0]\n",
    "    plt.text(i, 0.83, f'{best_metric:.3f}', ha='center', va='bottom', \n",
    "             fontsize=9, fontweight='bold', color='darkred')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('final_comparison_all_models.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43c354e",
   "metadata": {},
   "source": [
    "### Финальные ROC-кривые всех моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d406a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "for model_name, results in models_results.items():\n",
    "    y_test_proba = results['y_test_proba']\n",
    "    if y_test_proba is not None:\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_test_proba)\n",
    "        auc_score = roc_auc_score(y_test, y_test_proba)\n",
    "        \n",
    "        if 'Neural' in model_name:\n",
    "            plt.plot(fpr, tpr, label=f'{model_name} (AUC = {auc_score:.3f})', \n",
    "                    linewidth=3, linestyle='-', color='darkorange')\n",
    "        elif 'SVM' in model_name or 'KNN' in model_name:\n",
    "            plt.plot(fpr, tpr, label=f'{model_name} (AUC = {auc_score:.3f})', \n",
    "                    linewidth=2, linestyle='--')\n",
    "        else:\n",
    "            plt.plot(fpr, tpr, label=f'{model_name} (AUC = {auc_score:.3f})', \n",
    "                    linewidth=2)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Случайный классификатор', linewidth=2)\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('Финальные ROC-кривые всех моделей', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc='lower right', fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axis([0, 1, 0, 1])\n",
    "plt.savefig('final_roc_curves_all_models.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8530170",
   "metadata": {},
   "source": [
    "### Сохранение результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314dd15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_metrics_df.to_csv('final_classification_results.csv', index=False)\n",
    "print(\"\\nРезультаты сохранены в файл 'final_classification_results.csv'\")\n",
    "\n",
    "print(f\"Лучшая точность: {final_metrics_df['Test Accuracy'].max():.3%}\")\n",
    "print(f\"Лучшая модель по точности: {final_metrics_df.loc[final_metrics_df['Test Accuracy'].idxmax(), 'Model']}\")\n",
    "print(f\"Лучший AUC: {final_metrics_df['Test ROC-AUC'].max():.3%}\")\n",
    "print(f\"Лучшая модель по AUC: {final_metrics_df.loc[final_metrics_df['Test ROC-AUC'].idxmax(), 'Model']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
